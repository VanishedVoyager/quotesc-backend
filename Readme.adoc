= Quote-Management
:imagesdir: ./img
:source-highlighter: coderay
:toc:
Erik Mayrhofer <obyoxar@gmail.com>
:repolink: VanishedWanderer/quotesc-backend/master
:diagram-proxy: http://www.plantuml.com/plantuml/proxy?cache=no&src=https://raw.githubusercontent.com/{repolink}

== General Overview
As a basis for this assignment, I decided not to use my previous projects, because first I didn't
like my data model at all (it was so primitive), and second I am currently working on a private
project, which can be used for this like a charm.

This project is the backend for a quote manager. Such a tool was desired by me and my friends for quite a while
and recently I started working on it.

The long term idea is to transform our current solution for keeping track of funny quotes (a google-form
connected to a spreadsheet) to a progressive web-app.

== ERD
ifdef::env-github[]
image::{diagram-proxy}/doc/erd.puml[Please wait for diagram to be merged into master]
endif::[]
ifndef::env-github[]
plantuml::doc/erd.puml[]
endif::[]

== Class Diagram
[plantuml]
----
Person "n" o--o "m" Quote
Person <|-- User
Quote "n" -o "1" User
Person --o Nickname
class Quote {
    + text : String
    + quotedPersons : List<Person>
    + quoter : QuoteUser
}
class Person {
    + firstName : String
    + lastName : String
    + quotes : List<Quote>
}
class User {
    + sub : String
    + person : Person
}
class Nickname {
    + text : String
}
----
Description: A user (in my private Project will this be connected to keycloak) may
submit a quote. This quote has text and one or more People that were quoted.
A Person may correspond to an account, and be a user. People are traditionally
given Nicknames, which describe their most recent remarkable action
or are just insiders. One person can have more nicknames.

== Use Cases
[plantuml]
----

actor regus as "Registered User"
actor admin as "Administrator"

usecase UC1 as "Submit a Quote"
usecase UC2 as "Quote Query"
usecase UC3 as "View Statistics"
usecase UC4 as "Administer Quotes"

regus --> UC1
regus --> UC2
regus --> UC3

regus <|- admin

admin --> UC4
----
Description:

#1 Submit a Quote:: A registered user wants to sumit a quote, which is persisted and can be
viewed by others
#2 Quote Query:: A registered user wants to view quotes, filtered by person and date.
#3 View Statistics:: A registered user wants to view statistics, like average quote time,
most quoted person and so on.
#4 Administer Quotes:: A dedicated admin wants to be able to edit, and delete quotes.

I am using `jq` to format json output from commandline. (Can easily be installed via apt or brew)

=== Quote Endpoint
  GET, PUT, POST, DELETE http://localhost:8080/quotes[/{id}]

==== Get `UC2`
[source, shell]
----
curl -X GET \
  http://localhost:8080/quotes | jq
----
==== Post `UC1`
[source, shell]
----
curl -X POST \
  http://localhost:8080/quotes \
  -H 'Content-Type: application/json' \
  -d '{
    "text": "NewTestQuote",
    "quotedPersons": [
            {
                "id": 5
            }
        ],
        "quoter": {
            "id": 6
        }
}' | jq
----
WARNING: Be sure to use Person- and User-ids that exist in your run. You can see some of them when getting all quotes

==== Put `UC4`
[source, shell]
----
curl -X PUT \
  http://localhost:8080/quotes \
  -d '{
    "text": "PuttedChangedQuote",
    "quotedPersons": [
        {
            "id": 5
        }
    ],
    "quoter": {
        "id": 6
    },
    "id": 12
}' | jq
----
WARNING: Be sure to use Quote-, Person- and User-ids that exist in your run. You can see some of them when getting all quotes

==== Delete `UC4`
[source, shell]
----
curl -X DELETE \
  http://localhost:8080/quotes/12 \
  -H 'Content-Type: application/json' \
  -H 'cache-control: no-cache' | jq
----

=== Statistics Endpoint
==== Top People
Gibt die Quote-Anzahl pro Person zur√ºck.
[source, shell]
----
curl -X GET \
  http://localhost:8080/statistics/toppeople | jq
----


== Usage
=== Running the whole stack in production
. `mvn package` Builds the project. This will run the unit tests using an
in-memory h2-db and then package the application to `target/quotesc-backend-..-runner.jar`.
This jar will be needed by the next step.
. `docker-compose build` Will build the docker-image for quotesc.
. `docker-compose up` Will start a PostgreSQL-DB and the webserver.

=== Running in Dev-Mode
==== Starting the Database
The project directory contains a `docker-compose.yml` which
will pre default start the Database and also the Quarkus-Server.
We can prevent this from happening using

[source, shell]
----
docker-compose up postgres
----

which will only start the Database.

==== Running the project in dev mode
When the database was started, we can launch Quarkus development mode.
[source, shell]
----
./mvnw compile quarkus:dev
----

=== Database Connection in IDE

Create a new Datasource of type "PostgreSQL". Then add the
datasource like shown in the image. The database shipped with
the docker-compose file uses `app:passme` as credentials and
a database called `quotesc`.

image::DatasourceIntellij.png[Datasource in Intellij]

== Panache and Hibernate
I used Panache to access the `Nickname` entity.

There are two ways to use Panache, one is to directly extend `PanacheEntity`
which allows you to access the Persistence-Functions directly from the class.
[source,java]
----
person.persist();

// finding a specific person by ID
person = Person.findById(personId);

// finding all living persons
List<Person> livingPersons = Person.list("status", Status.Alive);
----
But i really am not keen on the idea of having this sort of code inside of my Entities.
I think they should serve one and only one purpose - that of storing data. And also
you have to derive from PanacheEntity which seems kind of inelegant.

Therefore i fell back to the second method of using Panache. I created my `NicknameDao`
and then let that extend `PanacheRepository<Nickname>` which really feels like using
SpringBoot's Data Api. Then I can use my Dao like always, but instead of having to fiddle
with JPQL and NamedQueries i can use Panache's fluent api to access the data.

I am a big fan of things like these, because it's way less error prone, you cannot
make any syntax errors - and if you do, they are found at compile time. Most of the
time it's more readable. Intellij's JPQL intellisense and semantic checking is making troubles
with kotlin at the time, so that's another point for Panache.
Panache also reduces the boilerplate code as normally you would have to write
`persist`, `update`, `findAll`, etc. for each single Dao you use. In the past I have found
myself creating simple abstract Daos, that did that for me. With panache all of this is
already implemented, so you can concentrate on business logic, instead of writing the same
thing for the 100th time.

I can see only two big downsides. When using `PanacheRepository` all of the flexibility
and the query-functions are exposed to other classes. While this can be a cool thing, because
everyone can build their queries where and whenever they like and doesn't have to program it into
the Dao, this can also be the source of bad programming, as code could be cluttered everywhere.
This is just a thing to keep in mind, but no real downside.

The big downside of panache is surely it's performance. Even Hibernate is relatively slow
compared to prepared and well written SQL-Statements but Hibernate still can prepare some
of it's logic at startup time. This is the reason why we normally use NamedStatements.
Panache on the other hand doesn't seem to do so, so all statements are generated while
running - hopefully they are cached - but this takes away precious cpu-time. And of course
adding another layer of generators will prevent perfect optimizing of SQL-Queries.
I didn't look into how Panache behaves with the "n+1"-Problem but I am not planning to do so
as of now for I really like Panache and would like to use it without having a bad conscience.

Another thing is, that `@Transactional` is contained within the Dao for Hibernate, but for
Panache this has to be written outside of the Repository. This can be a positive thing, as
Transactions are treated more seriously then, and maybe are really Transaction-Based
instead of method based.

Panache has near to no documentation. I wanted to use the `em.refresh()` using PanacheRepositories
but this is not documented anywhere. Not even Adam Bien's video for Panache is really informative.

I will try to use Panache in my private Projects, as it makes my code more clean and at this time
I am more worried about unclean code than about millisecond-performance. But if Panache want's to
fulfill my needs, it has to grow and get more flexible and documented.

An upside with Panache is that it supports paging and streaming out of the box which is really a
good thing.

Later edit:: I also ported `QuoteDao` to Panache as the amount of queries was growing, and
writing NamedQueries is just not as comfortable as using Panache. Instantly I could reduce
the monster of `QuoteDao` which had 50 lines of code (and basically no real business logic,
because the real logic was in the NamedQuery of Quote) to a small and concise class with only 15
Lines, which contained all of the logic that was needed.

== Using Jackson

I am using Jackson because it has `@JsonIgnoreProperties`. See Person and Nickname for Details.

== OpenAPI / Swagger
Look at the OpenAPI-Specifications at `localhost:8080/openapi`. A user interface is available at
`localhost:8080/swagger-ui`.

NOTE: I included `quarkus.swagger-ui.always-include=true` so swagger UI is also available in
production mode.